{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6e4daf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total questions extracted: 150\n",
      "\n",
      "--- Question 1 ---\n",
      "ID: 1\n",
      "Section: ENGLISH_COMPREHENSION\n",
      "Question: ## The Strange Case of Dr Jekyll and Mr Hyde\n",
      "\n",
      "by Robert Louis Stevenson\n",
      "\n",
      "*Dr Jekyll is a well-respec...\n",
      "Lead-in: In which city is the novel set?...\n",
      "Options: A=London, B=Manchester, C=Birmingham, D=Oxford, E=Cambridge\n",
      "\n",
      "--- Question 2 ---\n",
      "ID: 2\n",
      "Section: ENGLISH_COMPREHENSION\n",
      "Question: ## The Strange Case of Dr Jekyll and Mr Hyde\n",
      "\n",
      "by Robert Louis Stevenson\n",
      "\n",
      "*Dr Jekyll is a well-respec...\n",
      "Lead-in: What type of word is \"ferocity\" (line 2)?...\n",
      "Options: A=noun, B=preposition, C=verb, D=adverb, E=adjective\n",
      "\n",
      "--- Question 3 ---\n",
      "ID: 3\n",
      "Section: ENGLISH_COMPREHENSION\n",
      "Question: ## The Strange Case of Dr Jekyll and Mr Hyde\n",
      "\n",
      "by Robert Louis Stevenson\n",
      "\n",
      "*Dr Jekyll is a well-respec...\n",
      "Lead-in: The victim of the crime is described as being of “...\n",
      "Options: A=that he was on a high platform, B=that he was a man of the upper, C=that he always held his head u, D=that he was rich, E=that he was a man of the lower\n",
      "\n",
      "✓ Questions exported to questions.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Exam Parser Script\n",
    "===================\n",
    "\n",
    "Converts a Markdown exam output file into a list of Question objects.\n",
    "\n",
    "IMPORTANT: This script uses Python's dataclass instead of Pydantic BaseModel for \n",
    "portability. To use Pydantic BaseModel, replace the Question class definition with:\n",
    "\n",
    "    from pydantic import BaseModel\n",
    "    \n",
    "    class Question(BaseModel):\n",
    "        id: int\n",
    "        question: str\n",
    "        lead_in: str = \"\"\n",
    "        option_A: str = \"A\"\n",
    "        option_B: str = \"B\"\n",
    "        option_C: str = \"C\"\n",
    "        option_D: str = \"D\"\n",
    "        option_E: str = \"E\"\n",
    "        option_A_url: str = \"\"\n",
    "        option_B_url: str = \"\"\n",
    "        option_C_url: str = \"\"\n",
    "        option_D_url: str = \"\"\n",
    "        option_E_url: str = \"\"\n",
    "        section_id: str = \"\"\n",
    "\n",
    "Then install pydantic: pip install pydantic\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "from typing import List, Optional, Tuple\n",
    "from dataclasses import dataclass, field, asdict\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Question:\n",
    "    id: int\n",
    "    question: str\n",
    "    lead_in: str = \"\"\n",
    "    option_A: str = \"A\"\n",
    "    option_B: str = \"B\"\n",
    "    option_C: str = \"C\"\n",
    "    option_D: str = \"D\"\n",
    "    option_E: str = \"E\"\n",
    "    option_A_url: str = \"\"\n",
    "    option_B_url: str = \"\"\n",
    "    option_C_url: str = \"\"\n",
    "    option_D_url: str = \"\"\n",
    "    option_E_url: str = \"\"\n",
    "    section_id: str = \"\"\n",
    "    \n",
    "    def dict(self):\n",
    "        \"\"\"Convert to dictionary for JSON serialization.\"\"\"\n",
    "        return asdict(self)\n",
    "\n",
    "\n",
    "# Robust question splitting regex from question_split.py\n",
    "QUESTION_SPLIT = re.compile(\n",
    "    r'''\n",
    "    (?:\n",
    "        # ── HTML-wrapped number: must be ONLY digits\n",
    "        <(?:p|b)>\\s*(\\d+)\\s*</(?:p|b)>\n",
    "\n",
    "      | # ── markdown bold number: must be ONLY digits\n",
    "        \\*\\*\\s*(\\d+)\\s*\\*\\*\n",
    "\n",
    "      | # ── plain / heading number (line-based)\n",
    "        ^\\s*(?:\\#+\\s*)?\n",
    "        (\\d+)\n",
    "        (?!\\.)\n",
    "        (?:\n",
    "            \\s*$                # number-only line\n",
    "          | \\s+(?!\\d)            # not a sequence\n",
    "             (?!cm\\b|mm\\b|m\\b|kg\\b|g\\b|%)\n",
    "          | \\n+\n",
    "        )\n",
    "    )\n",
    "    ''',\n",
    "    re.VERBOSE | re.MULTILINE | re.IGNORECASE\n",
    ")\n",
    "\n",
    "\n",
    "def extract_questions_with_numbers(text: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"Extract questions with their numbers from text.\"\"\"\n",
    "    splits = QUESTION_SPLIT.split(text)\n",
    "    results = []\n",
    "\n",
    "    i = 1\n",
    "    while i < len(splits):\n",
    "        group = splits[i:i+3]\n",
    "        q_num = next((g for g in group if g is not None), None)\n",
    "        block = splits[i + 3] if i + 3 < len(splits) else \"\"\n",
    "\n",
    "        if q_num:\n",
    "            results.append((q_num.strip(), block.strip()))\n",
    "\n",
    "        i += 4\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def extract_image_urls(text: str) -> List[str]:\n",
    "    \"\"\"Extract all image URLs from markdown text.\"\"\"\n",
    "    # Pattern: ![...](URL)\n",
    "    pattern = r'!\\[.*?\\]\\((https?://[^\\s\\)]+)\\)'\n",
    "    urls = re.findall(pattern, text)\n",
    "    return urls\n",
    "\n",
    "\n",
    "def remove_image_markdown(text: str) -> str:\n",
    "    \"\"\"Remove image markdown but keep the URLs for later processing.\"\"\"\n",
    "    # Remove ![description](url) patterns\n",
    "    text = re.sub(r'!\\[.*?\\]\\([^\\)]+\\)', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def embed_images_as_html(urls: List[str]) -> str:\n",
    "    \"\"\"Convert image URLs to HTML img tags.\"\"\"\n",
    "    if not urls:\n",
    "        return \"\"\n",
    "    html_images = []\n",
    "    for url in urls:\n",
    "        html_images.append(f'<p><img src=\"{url}\"></p>')\n",
    "    return '\\n'.join(html_images)\n",
    "\n",
    "\n",
    "def parse_options(text: str) -> dict:\n",
    "    \"\"\"Parse options from text. Returns dict with option_A through option_E.\"\"\"\n",
    "    options = {\n",
    "        'option_A': 'A',\n",
    "        'option_B': 'B',\n",
    "        'option_C': 'C',\n",
    "        'option_D': 'D',\n",
    "        'option_E': 'E'\n",
    "    }\n",
    "    \n",
    "    # Pattern for options: - A text or - A) text\n",
    "    option_pattern = r'^\\s*-\\s*([A-E])[\\)\\.]?\\s+(.+?)$'\n",
    "    \n",
    "    lines = text.split('\\n')\n",
    "    for line in lines:\n",
    "        match = re.match(option_pattern, line.strip())\n",
    "        if match:\n",
    "            letter = match.group(1)\n",
    "            value = match.group(2).strip()\n",
    "            options[f'option_{letter}'] = value\n",
    "    \n",
    "    return options\n",
    "\n",
    "\n",
    "def parse_table_options(text: str) -> dict:\n",
    "    \"\"\"Parse options from markdown tables (for NVR-style vertical tables).\"\"\"\n",
    "    options = {\n",
    "        'option_A': 'A',\n",
    "        'option_B': 'B',\n",
    "        'option_C': 'C',\n",
    "        'option_D': 'D',\n",
    "        'option_E': 'E'\n",
    "    }\n",
    "    \n",
    "    lines = text.split('\\n')\n",
    "    table_data = []\n",
    "    \n",
    "    for line in lines:\n",
    "        if '|' in line and not line.strip().startswith('|---'):\n",
    "            cells = [cell.strip() for cell in line.split('|')]\n",
    "            cells = [c for c in cells if c]  # Remove empty cells\n",
    "            if cells:\n",
    "                table_data.append(cells)\n",
    "    \n",
    "    # Check if last row is A B C D E (option labels)\n",
    "    if table_data and len(table_data[-1]) == 5:\n",
    "        last_row = table_data[-1]\n",
    "        if last_row == ['A', 'B', 'C', 'D', 'E']:\n",
    "            # This is vertical format\n",
    "            if len(table_data) >= 2:\n",
    "                # Second to last row contains the actual options\n",
    "                option_values = table_data[-2]\n",
    "                for i, letter in enumerate(['A', 'B', 'C', 'D', 'E']):\n",
    "                    if i < len(option_values):\n",
    "                        options[f'option_{letter}'] = option_values[i]\n",
    "    \n",
    "    return options\n",
    "\n",
    "\n",
    "def extract_section(text: str, section_name: str, next_section: Optional[str] = None) -> str:\n",
    "    \"\"\"Extract a section from the markdown text.\"\"\"\n",
    "    # Try different heading levels\n",
    "    patterns = [\n",
    "        rf'^#\\s+{re.escape(section_name)}\\s*$',  # # SECTION\n",
    "        rf'^##\\s+{re.escape(section_name)}\\s*$',  # ## SECTION\n",
    "    ]\n",
    "    \n",
    "    match = None\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)\n",
    "        if match:\n",
    "            break\n",
    "    \n",
    "    if not match:\n",
    "        return \"\"\n",
    "    \n",
    "    start = match.end()\n",
    "    \n",
    "    if next_section:\n",
    "        # Try both heading levels for next section\n",
    "        next_patterns = [\n",
    "            rf'^#\\s+{re.escape(next_section)}\\s*$',\n",
    "            rf'^##\\s+{re.escape(next_section)}\\s*$',\n",
    "        ]\n",
    "        for next_pattern in next_patterns:\n",
    "            next_match = re.search(next_pattern, text[start:], re.IGNORECASE | re.MULTILINE)\n",
    "            if next_match:\n",
    "                end = start + next_match.start()\n",
    "                return text[start:end]\n",
    "    \n",
    "    return text[start:]\n",
    "\n",
    "\n",
    "def parse_comprehension(text: str, start_id: int) -> List[Question]:\n",
    "    \"\"\"Parse comprehension section.\"\"\"\n",
    "    questions = []\n",
    "    \n",
    "    # Find the passage (everything before \"Please answer these questions\")\n",
    "    passage_end = re.search(r'Please answer these questions', text, re.IGNORECASE)\n",
    "    if not passage_end:\n",
    "        return questions\n",
    "    \n",
    "    passage_text = text[:passage_end.start()].strip()\n",
    "    \n",
    "    # Remove \"Read this passage carefully\" line\n",
    "    passage_text = re.sub(r'^.*?Read this passage carefully.*?\\n', '', passage_text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Clean the passage - remove image descriptions but keep passage content\n",
    "    lines = passage_text.split('\\n')\n",
    "    cleaned_lines = []\n",
    "    for line in lines:\n",
    "        # Skip image markdown and descriptions\n",
    "        if line.strip().startswith('![') or 'cloudinary' in line:\n",
    "            continue\n",
    "        # Skip lines that are just image descriptions\n",
    "        if re.match(r'^[A-Z].*\\.(jpg|png|gif)$', line.strip()):\n",
    "            continue\n",
    "        cleaned_lines.append(line)\n",
    "    \n",
    "    passage = '\\n'.join(cleaned_lines).strip()\n",
    "    \n",
    "    # Extract questions after \"Please answer these questions\"\n",
    "    questions_text = text[passage_end.end():]\n",
    "    \n",
    "    # Extract individual questions\n",
    "    q_list = extract_questions_with_numbers(questions_text)\n",
    "    \n",
    "    for q_num, q_block in q_list:\n",
    "        # Split question text from options\n",
    "        lines = q_block.split('\\n')\n",
    "        question_text = []\n",
    "        options_started = False\n",
    "        options_text = []\n",
    "        \n",
    "        for line in lines:\n",
    "            if line.strip().startswith('- ') and re.match(r'^\\s*-\\s*[A-E][\\)\\.]?\\s+', line):\n",
    "                options_started = True\n",
    "            \n",
    "            if options_started:\n",
    "                options_text.append(line)\n",
    "            else:\n",
    "                question_text.append(line)\n",
    "        \n",
    "        lead_in = '\\n'.join(question_text).strip()\n",
    "        options = parse_options('\\n'.join(options_text))\n",
    "        \n",
    "        q = Question(\n",
    "            id=start_id,\n",
    "            question=passage,\n",
    "            lead_in=lead_in,\n",
    "            section_id=\"ENGLISH_COMPREHENSION\",\n",
    "            **options\n",
    "        )\n",
    "        questions.append(q)\n",
    "        start_id += 1\n",
    "    \n",
    "    return questions\n",
    "\n",
    "\n",
    "def parse_spelling(text: str, start_id: int) -> List[Question]:\n",
    "    \"\"\"Parse spelling section.\"\"\"\n",
    "    questions = []\n",
    "    \n",
    "    # Extract questions\n",
    "    q_list = extract_questions_with_numbers(text)\n",
    "    \n",
    "    for q_num, q_block in q_list:\n",
    "        # For spelling, the sentence is the question and options are just A B C D\n",
    "        # followed by an implicit N option\n",
    "        lines = [line.strip() for line in q_block.split('\\n') if line.strip()]\n",
    "        \n",
    "        # The first line is usually the sentence\n",
    "        question = lines[0] if lines else \"\"\n",
    "        \n",
    "        # Options for spelling/punctuation are special:\n",
    "        # A, B, C, D refer to parts of the sentence\n",
    "        # E is always \"N\" (no mistake)\n",
    "        options = {\n",
    "            'option_A': 'A',\n",
    "            'option_B': 'B', \n",
    "            'option_C': 'C',\n",
    "            'option_D': 'D',\n",
    "            'option_E': 'N'  # Always N for \"no mistake\"\n",
    "        }\n",
    "        \n",
    "        q = Question(\n",
    "            id=start_id,\n",
    "            question=question,\n",
    "            section_id=\"ENGLISH_SPELLING\",\n",
    "            **options\n",
    "        )\n",
    "        questions.append(q)\n",
    "        start_id += 1\n",
    "    \n",
    "    return questions\n",
    "\n",
    "\n",
    "def parse_punctuation(text: str, start_id: int) -> List[Question]:\n",
    "    \"\"\"Parse punctuation section.\"\"\"\n",
    "    questions = []\n",
    "    \n",
    "    # Extract questions\n",
    "    q_list = extract_questions_with_numbers(text)\n",
    "    \n",
    "    for q_num, q_block in q_list:\n",
    "        # For punctuation, the sentence is the question and options are just A B C D\n",
    "        # followed by an implicit N option\n",
    "        lines = [line.strip() for line in q_block.split('\\n') if line.strip()]\n",
    "        \n",
    "        # The first line is usually the sentence\n",
    "        question = lines[0] if lines else \"\"\n",
    "        \n",
    "        # Options for spelling/punctuation are special:\n",
    "        # A, B, C, D refer to parts of the sentence\n",
    "        # E is always \"N\" (no mistake)\n",
    "        options = {\n",
    "            'option_A': 'A',\n",
    "            'option_B': 'B',\n",
    "            'option_C': 'C',\n",
    "            'option_D': 'D',\n",
    "            'option_E': 'N'  # Always N for \"no mistake\"\n",
    "        }\n",
    "        \n",
    "        q = Question(\n",
    "            id=start_id,\n",
    "            question=question,\n",
    "            section_id=\"ENGLISH_PUNCTUATION\",\n",
    "            **options\n",
    "        )\n",
    "        questions.append(q)\n",
    "        start_id += 1\n",
    "    \n",
    "    return questions\n",
    "\n",
    "\n",
    "def parse_cloze(text: str, start_id: int) -> List[Question]:\n",
    "    \"\"\"Parse cloze section.\"\"\"\n",
    "    questions = []\n",
    "    \n",
    "    # Find the passage (everything before question numbers start)\n",
    "    passage_lines = []\n",
    "    questions_started = False\n",
    "    \n",
    "    lines = text.split('\\n')\n",
    "    passage_text = []\n",
    "    questions_text = []\n",
    "    \n",
    "    for line in lines:\n",
    "        # Check if question numbering starts\n",
    "        if re.match(r'^\\s*\\d+\\s*$', line.strip()) or re.match(r'^\\*\\*\\s*\\d+\\s*\\*\\*', line.strip()):\n",
    "            questions_started = True\n",
    "        \n",
    "        if questions_started:\n",
    "            questions_text.append(line)\n",
    "        else:\n",
    "            passage_text.append(line)\n",
    "    \n",
    "    passage = '\\n'.join(passage_text).strip()\n",
    "    # Remove \"In this passage you have to choose\" instruction\n",
    "    passage = re.sub(r'^.*?In this passage you have to choose.*?\\n', '', passage, flags=re.IGNORECASE)\n",
    "    passage = re.sub(r'^.*?Choose the.*?answer sheet\\.\\s*\\n', '', passage, flags=re.IGNORECASE | re.MULTILINE)\n",
    "    \n",
    "    # For cloze, extract the passage text (title + body)\n",
    "    # The passage contains blanks marked by question numbers\n",
    "    \n",
    "    # Extract questions\n",
    "    q_list = extract_questions_with_numbers('\\n'.join(questions_text))\n",
    "    \n",
    "    for q_num, q_block in q_list:\n",
    "        # Check if options are in table format or plain text format\n",
    "        if '|' in q_block:\n",
    "            # Table format - parse the table\n",
    "            options = parse_table_options(q_block)\n",
    "            \n",
    "            # Get the context before the table\n",
    "            table_start = q_block.find('|')\n",
    "            lead_in = q_block[:table_start].strip()\n",
    "        else:\n",
    "            # Plain text format - options are just single letters A B C D E\n",
    "            # Each on a separate line\n",
    "            lines = [l.strip() for l in q_block.split('\\n') if l.strip()]\n",
    "            \n",
    "            # Find where the single-letter options start\n",
    "            option_lines = []\n",
    "            context_lines = []\n",
    "            found_options = False\n",
    "            \n",
    "            for line in lines:\n",
    "                # Check if line is a single letter A-E\n",
    "                if line in ['A', 'B', 'C', 'D', 'E']:\n",
    "                    found_options = True\n",
    "                    option_lines.append(line)\n",
    "                elif not found_options:\n",
    "                    context_lines.append(line)\n",
    "                else:\n",
    "                    # After options, this might be continuation of passage\n",
    "                    pass\n",
    "            \n",
    "            lead_in = '\\n'.join(context_lines).strip()\n",
    "            \n",
    "            # For plain text single-letter options in cloze, \n",
    "            # we don't have the actual option text, just placeholders\n",
    "            options = {\n",
    "                'option_A': 'A',\n",
    "                'option_B': 'B',\n",
    "                'option_C': 'C',\n",
    "                'option_D': 'D',\n",
    "                'option_E': 'E'\n",
    "            }\n",
    "        \n",
    "        q = Question(\n",
    "            id=start_id,\n",
    "            question=passage,\n",
    "            lead_in=lead_in,\n",
    "            section_id=\"ENGLISH_CLOZE\",\n",
    "            **options\n",
    "        )\n",
    "        questions.append(q)\n",
    "        start_id += 1\n",
    "    \n",
    "    return questions\n",
    "\n",
    "\n",
    "def parse_english_section(text: str, start_id: int) -> List[Question]:\n",
    "    \"\"\"Parse the entire ENGLISH section.\"\"\"\n",
    "    questions = []\n",
    "    \n",
    "    # Find comprehension section\n",
    "    comp_start = re.search(r'Read this passage carefully', text, re.IGNORECASE)\n",
    "    spell_start = re.search(r'Spelling Exercises', text, re.IGNORECASE)\n",
    "    punct_start = re.search(r'In these sentences there are some \\*\\*punctuation\\*\\* mistakes', text, re.IGNORECASE)\n",
    "    cloze_start = re.search(r'In this passage you have to choose the \\*\\*best\\*\\* word', text, re.IGNORECASE)\n",
    "    \n",
    "    if comp_start and spell_start:\n",
    "        comp_text = text[comp_start.start():spell_start.start()]\n",
    "        comp_questions = parse_comprehension(comp_text, start_id)\n",
    "        questions.extend(comp_questions)\n",
    "        start_id += len(comp_questions)\n",
    "    \n",
    "    if spell_start and punct_start:\n",
    "        spell_text = text[spell_start.start():punct_start.start()]\n",
    "        spell_questions = parse_spelling(spell_text, start_id)\n",
    "        questions.extend(spell_questions)\n",
    "        start_id += len(spell_questions)\n",
    "    \n",
    "    if punct_start and cloze_start:\n",
    "        punct_text = text[punct_start.start():cloze_start.start()]\n",
    "        punct_questions = parse_punctuation(punct_text, start_id)\n",
    "        questions.extend(punct_questions)\n",
    "        start_id += len(punct_questions)\n",
    "    \n",
    "    if cloze_start:\n",
    "        # Find end of cloze (start of next section or end of text)\n",
    "        # Look for ## VERBAL REASONING or end of English section\n",
    "        cloze_text = text[cloze_start.start():]\n",
    "        \n",
    "        cloze_questions = parse_cloze(cloze_text, start_id)\n",
    "        questions.extend(cloze_questions)\n",
    "        start_id += len(cloze_questions)\n",
    "    \n",
    "    return questions\n",
    "\n",
    "\n",
    "def parse_mathematics_section(text: str, start_id: int) -> List[Question]:\n",
    "    \"\"\"Parse MATHEMATICS section.\"\"\"\n",
    "    questions = []\n",
    "    \n",
    "    # Extract questions\n",
    "    q_list = extract_questions_with_numbers(text)\n",
    "    \n",
    "    for q_num, q_block in q_list:\n",
    "        # Extract image URLs first\n",
    "        image_urls = extract_image_urls(q_block)\n",
    "        \n",
    "        # Remove image markdown\n",
    "        cleaned_block = remove_image_markdown(q_block)\n",
    "        \n",
    "        # Split question text from options\n",
    "        lines = cleaned_block.split('\\n')\n",
    "        question_lines = []\n",
    "        options_text = []\n",
    "        options_started = False\n",
    "        \n",
    "        for line in lines:\n",
    "            if line.strip().startswith('- ') and re.match(r'^\\s*-\\s*[A-E][\\)\\.]?\\s+', line):\n",
    "                options_started = True\n",
    "            \n",
    "            if options_started:\n",
    "                options_text.append(line)\n",
    "            else:\n",
    "                question_lines.append(line)\n",
    "        \n",
    "        # Build question with images embedded\n",
    "        question_text = '\\n'.join(question_lines).strip()\n",
    "        \n",
    "        # Add images before question text\n",
    "        if image_urls:\n",
    "            images_html = embed_images_as_html(image_urls)\n",
    "            question_text = images_html + '\\n' + question_text\n",
    "        \n",
    "        options = parse_options('\\n'.join(options_text))\n",
    "        \n",
    "        q = Question(\n",
    "            id=start_id,\n",
    "            question=question_text,\n",
    "            section_id=\"MATHEMATICS\",\n",
    "            **options\n",
    "        )\n",
    "        questions.append(q)\n",
    "        start_id += 1\n",
    "    \n",
    "    return questions\n",
    "\n",
    "\n",
    "def parse_verbal_reasoning_section(text: str, start_id: int) -> List[Question]:\n",
    "    \"\"\"Parse VERBAL REASONING section.\"\"\"\n",
    "    questions = []\n",
    "    \n",
    "    # Extract questions\n",
    "    q_list = extract_questions_with_numbers(text)\n",
    "    \n",
    "    for q_num, q_block in q_list:\n",
    "        # Extract image URLs first\n",
    "        image_urls = extract_image_urls(q_block)\n",
    "        \n",
    "        # Remove image markdown\n",
    "        cleaned_block = remove_image_markdown(q_block)\n",
    "        \n",
    "        # Split question text from options\n",
    "        lines = cleaned_block.split('\\n')\n",
    "        question_lines = []\n",
    "        options_text = []\n",
    "        options_started = False\n",
    "        \n",
    "        for line in lines:\n",
    "            if line.strip().startswith('- ') and re.match(r'^\\s*-\\s*[A-E][\\)\\.]?\\s+', line):\n",
    "                options_started = True\n",
    "            \n",
    "            if options_started:\n",
    "                options_text.append(line)\n",
    "            else:\n",
    "                question_lines.append(line)\n",
    "        \n",
    "        # Build question with images embedded\n",
    "        question_text = '\\n'.join(question_lines).strip()\n",
    "        \n",
    "        # Add images before question text\n",
    "        if image_urls:\n",
    "            images_html = embed_images_as_html(image_urls)\n",
    "            question_text = images_html + '\\n' + question_text\n",
    "        \n",
    "        options = parse_options('\\n'.join(options_text))\n",
    "        \n",
    "        q = Question(\n",
    "            id=start_id,\n",
    "            question=question_text,\n",
    "            section_id=\"VERBAL_REASONING\",\n",
    "            **options\n",
    "        )\n",
    "        questions.append(q)\n",
    "        start_id += 1\n",
    "    \n",
    "    return questions\n",
    "\n",
    "\n",
    "def parse_exam(file_path: str) -> List[Question]:\n",
    "    \"\"\"Main function to parse the exam markdown file.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    all_questions = []\n",
    "    current_id = 1\n",
    "    \n",
    "    # Extract ENGLISH section (from # ENGLISH to ## VERBAL REASONING)\n",
    "    english_text = extract_section(content, \"ENGLISH\", \"VERBAL REASONING\")\n",
    "    if english_text:\n",
    "        english_questions = parse_english_section(english_text, current_id)\n",
    "        all_questions.extend(english_questions)\n",
    "        current_id += len(english_questions)\n",
    "    \n",
    "    # Extract VERBAL REASONING section (from ## VERBAL REASONING to ## MATHEMATICS)\n",
    "    vr_text = extract_section(content, \"VERBAL REASONING\", \"MATHEMATICS\")\n",
    "    if vr_text:\n",
    "        vr_questions = parse_verbal_reasoning_section(vr_text, current_id)\n",
    "        all_questions.extend(vr_questions)\n",
    "        current_id += len(vr_questions)\n",
    "    \n",
    "    # Extract MATHEMATICS section (from ## MATHEMATICS to ## NON-VERBAL REASONING or end)\n",
    "    math_text = extract_section(content, \"MATHEMATICS\", \"NON-VERBAL REASONING\")\n",
    "    if not math_text:\n",
    "        # Try without next section (in case NVR doesn't exist)\n",
    "        math_text = extract_section(content, \"MATHEMATICS\")\n",
    "    \n",
    "    if math_text:\n",
    "        math_questions = parse_mathematics_section(math_text, current_id)\n",
    "        all_questions.extend(math_questions)\n",
    "        current_id += len(math_questions)\n",
    "    \n",
    "    return all_questions\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Parse the exam\n",
    "    questions = parse_exam(\"output.md\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"Total questions extracted: {len(questions)}\")\n",
    "    \n",
    "    # Print first few questions for verification\n",
    "    for i, q in enumerate(questions[:3]):\n",
    "        print(f\"\\n--- Question {i+1} ---\")\n",
    "        print(f\"ID: {q.id}\")\n",
    "        print(f\"Section: {q.section_id}\")\n",
    "        print(f\"Question: {q.question[:100]}...\")\n",
    "        print(f\"Lead-in: {q.lead_in[:50]}...\" if q.lead_in else \"Lead-in: (empty)\")\n",
    "        print(f\"Options: A={q.option_A[:30]}, B={q.option_B[:30]}, C={q.option_C[:30]}, D={q.option_D[:30]}, E={q.option_E[:30]}\")\n",
    "    \n",
    "    # Export to JSON (optional)\n",
    "    import json\n",
    "    with open(\"questions.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump([q.dict() for q in questions], f, indent=2, ensure_ascii=False)\n",
    "    print(\"\\n✓ Questions exported to questions.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee88c30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"questions.json\")\n",
    "\n",
    "df = df[['question', 'lead_in', 'option_A', 'option_B', 'option_C', 'option_D', 'option_E', 'option_A_url', 'option_B_url', 'option_C_url', 'option_D_url', 'option_E_url', 'section_id']]\n",
    "# Rename columns\n",
    "df = df.rename(columns={\n",
    "    \"question\": \"Question\",\n",
    "    \"lead_in\": \"Lead In\",\n",
    "    \"option_A\": \"Option A\",\n",
    "    \"option_B\": \"Option B\",\n",
    "    \"option_C\": \"Option C\",\n",
    "    \"option_D\": \"Option D\",\n",
    "    \"option_E\": \"Option E\",\n",
    "    \"option_A_url\": \"Option A Image URL\",\n",
    "    \"option_B_url\": \"Option B Image URL\",\n",
    "    \"option_C_url\": \"Option C Image URL\",\n",
    "    \"option_D_url\": \"Option D Image URL\",\n",
    "    \"option_E_url\": \"Option E Image URL\",\n",
    "    \"section_id\": \"Section External ID\"\n",
    "})\n",
    "\n",
    "df.to_csv(\"output_final.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add1cf09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
